{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convLayer(X,num_input_channels,num_filters,filter_shape,pool_shape,name):\n",
    "\n",
    "    conv_filt_shape = [filter_shape[0], filter_shape[1], num_input_channels,\n",
    "                      num_filters]\n",
    "    b1 = tf.Variable(tf.zeros([num_filters]))\n",
    "    filter1 = tf.get_variable(\"filter\"+name,shape=conv_filt_shape,dtype = tf.float32,initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    conv1 = tf.nn.conv2d(X,filter1,strides=[1,1,1,1],padding = \"SAME\")\n",
    "    conv1 += b1\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    ksize = [1, pool_shape[0], pool_shape[1], 1]\n",
    "    strides = [1, 2, 2, 1]\n",
    "    pool1 = tf.nn.max_pool(conv1,ksize=ksize,strides=strides,padding=\"SAME\")\n",
    "    return pool1\n",
    "\n",
    "def faceDetect(img, face_classifier):\n",
    "    img_faces=[]\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=3);\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 100, 100, 64)\n",
      "(?, 50, 50, 64)\n",
      "(?, 25, 25, 32)\n",
      "(?, 13, 13, 16)\n",
      "(?, 7, 7, 8)\n"
     ]
    }
   ],
   "source": [
    "labels=['Asjad','Fahad','Minahil','Umer']\n",
    "total_classes = len(labels)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "learning_rate = tf.placeholder(tf.float32,[])\n",
    "X = tf.placeholder(tf.float32,[None,200,200,3])\n",
    "Y = tf.placeholder(tf.float32,[None,total_classes])\n",
    "conv1 = convLayer(X,3,64,[3,3],[2,2],\"1\")\n",
    "print (conv1.shape)\n",
    "conv2 = convLayer(conv1,64,64,[3,3],[2,2],\"2\")\n",
    "print (conv2.shape)\n",
    "conv3 = convLayer(conv2,64,32,[3,3],[2,2],\"3\")\n",
    "print (conv3.shape)\n",
    "conv4 = convLayer(conv3,32,16,[3,3],[2,2],\"4\")\n",
    "print (conv4.shape)\n",
    "conv5 = convLayer(conv4,16,8,[3,3],[2,2],\"5\")\n",
    "print (conv5.shape)\n",
    "flattened = tf.reshape(conv5,[-1,7*7*8])\n",
    "\n",
    "dense1 = tf.layers.dense(flattened,total_classes)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = dense1,labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "\n",
    "a = tf.argmax(dense1,axis=1)\n",
    "b = tf.argmax(Y,axis=1)\n",
    "prediction = tf.equal(a,b)\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction,tf.float32))\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Models/best_model7.0.ckpt\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 400) #WIDTH\n",
    "cap.set(4, 600) #HEIGHT\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('C:/Users/Fahad/Anaconda2/envs/mypython35/Library/etc/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "sess=tf.Session()\n",
    "saver.restore(sess,'./Models/best_model7.0.ckpt')\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame,1)\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceDetect(frame, face_cascade)\n",
    "    # Display the resulting frame\n",
    "    for x,y,w,h in faces:\n",
    "         cv2.rectangle(frame,(x,y),(x+w,y+h),(173,255,51),2)\n",
    "         colored_face = frame[y:y+h, x:x+w]\n",
    "         colored_face = cv2.resize(colored_face,(200,200))\n",
    "         \n",
    "    values=sess.run(dense1,feed_dict={X:colored_face[np.newaxis,:,:,:]})\n",
    "    value=np.argmax(values)\n",
    "    score_array=np.array((value,value,value,value))\n",
    "    score=np.sum(score_array-values)\n",
    "    if (score*10)<100:\n",
    "        cv2.putText(frame,\"Name: \"+labels[value],(x,y-5), 2, 1,(173,255,51),2,cv2.LINE_AA)\n",
    "        cv2.putText(frame,\"Score: \"+str(int(abs(score*10))),(50,450), 2, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.flip(frame,0)\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
